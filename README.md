# Getting Started with Deep Learning with PyTorch and Hugging Face

This repository contains instructions/examples/tutorials for getting started with Deep Learning using PyTorch and Hugging Face libraries like [transformers](https://huggingface.co/docs/transformers/index), [datasets](https://huggingface.co/docs/datasets/index).

### Training Examples

* [Fine-tune FLAN-T5 XL/XXL using DeepSpeed & Hugging Face Transformers](./training/deepseed-flan-t5-summarization.ipynb)
* [Fine-tune FLAN-T5 for chat & dialogue summarization](./training/flan-t5-samsum-summarization.ipynb)
* [Fine-tune Falcon 180B with DeepSpeed ZeRO, LoRA & Flash Attention](./training/deepseed-falcon-180b-lora-fa.ipynb)
* [Getting started with Transformers and TPU using PyTorch](./training/accelerate-tpu-bert-text-classification.ipynb)
* [Extended Guide: Instruction-tune Llama 2](./training/instruction-tune-llama-2-int4.ipynb)
* [Quantize open LLMs using optimum and GPTQ](./training/optimize-llama-2-gptq.ipynb)
* [Fine-tune Embedding models for RAG](./training/fine-tune-embedding-model-for-rag.ipynb)
* [Fine-tune LLMs in 2024 with TRL](./training/fine-tune-llms-in-2024-with-trl.ipynb)
* [Fine-tune LLMs in 2025](./training/fine-tune-llms-in-2025.ipynb)
* [Fine-tune Multimodal LLMs with TRL](./training/fine-tune-multimodal-llms-with-trl.ipynb)
* [RLHF in 2024 with DPO & Hugging Face](./training/dpo-align-llms-in-2024-with-trl.ipynb)
* [Fine-tune Gemma with ChatML](./training/gemma-lora-example.ipynb)
* [Efficiently scale distributed training with FSDP & Q-LoRA](./training/fsdp-qlora-distributed-llama3.ipynb)
* [Fine-tune classifier with ModernBERT in 2025](./training/fine-tune-modern-bert-in-2025.ipynb)
* [How to align open LLMs in 2025 with DPO & Hugging Face](https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/rl-with-llms-in-2025-dpo.ipynb)

### Inference Examples

* [Text Generation Inference Examples](./inference/README.md)
* [FP8 Inference Benchmarks](./inference/fp8-inference.md)
* [Idefics Inference](./inference/idefics.md)
* [Llama 2 Inference](./inference/llama-7b.md)
* [Speculative Decoding](./inference/speculative.md)
* [StarCoder GPTQ Inference](./inference/starcoder_gptq.md)
